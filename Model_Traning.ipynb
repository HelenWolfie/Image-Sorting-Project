{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\npath = './'\nos.makedirs(os.path.join(path, 'DataRes_Research_Assessment', 'data'), exist_ok=True)\nroot_dir = os.path.join(path, 'DataRes_Research_Assessment')\n\n\n!pip3 install --upgrade gdown --quiet\n!gdown 1z3B1GR7UtHZGrqNjUaep6thHwrN3IYSI\n\nimport tarfile\nfrom tqdm import tqdm\n\ntar = tarfile.open(\"data.tar.gz\", \"r:gz\")\ntotal_size = sum(f.size for f in tar.getmembers())\nwith tqdm(total=total_size, unit=\"B\", unit_scale=True, desc=\"Extracting tar.gz file\") as pbar:\n    for member in tar.getmembers():\n        tar.extract(member, os.path.join(root_dir, 'data'))\n        pbar.update(member.size)\ntar.close()\n\nimport urllib.request\n\nimport os\nimport pickle\n\nimport numpy as np\n\ndef load_subcategories(txt_path):\n    subcategories = {}\n    file = open(txt_path, 'r')\n    lines = file.readlines()\n    for i, l in enumerate(lines):\n        info = l.split()\n        info[0] = info[0][3:]\n        subcategories.update({info[0]: {'ori_class_id': int(info[1]), 'class_id': i}})\n\n    return subcategories\n\n\nfrom tqdm import trange\nimport cv2\nimport random\n\ndef select_samples(subcategories, root_dir, split, n_images_per_subcategory):\n    samples = []\n    if split == \"train\":\n        train_dir = os.path.join(root_dir, \"data\", \"images\", \"train\")\n        for i in subcategories:\n            child_dir = os.path.join(train_dir, i[0], i)\n            pics = random.sample(os.listdir(child_dir), n_images_per_subcategory)\n            for j in pics:\n                samples.append((cv2.resize(cv2.imread(os.path.join(child_dir, j)), (32,32)).flatten().tolist(), subcategories[i][\"class_id\"]))\n    elif split == \"val\":\n        val_dir = os.path.join(root_dir, \"data\", \"images\")\n        file = open(os.path.join(root_dir, \"data\", \"val.txt\"), 'r')\n        lines = file.readlines()\n        val_data = []\n        for i in lines:\n            val_data.append(i.split())\n        random.shuffle(val_data)\n        for i in subcategories:\n            old_id = subcategories[i][\"ori_class_id\"]\n            count = 0\n            for j in val_data:\n                if int(j[1]) == old_id:\n                    samples.append((cv2.resize(cv2.imread(os.path.join(val_dir, j[0])), (32,32)).flatten().tolist(), subcategories[i][\"class_id\"]))\n                    count += 1\n                if count >= n_images_per_subcategory:\n                    break\n    return samples\n\ndef create_tinyplaces(samples, binary=True):\n    data, labels = [], []\n    for i in samples:\n        data.append(i[0])\n        if binary:\n            if i[1] >= 10:\n                labels.append(1)\n            else:\n                labels.append(0)\n        else:\n            labels.append(i[1])\n    data = np.array(data)\n    labels = np.array(labels)\n    dataset = {\"data\": data, \"label\": labels}\n\n    return dataset\n\n\n# Set the root directory of the dataset\nroot_dir = './DataRes_Research_Assessment/data'\n\n# Load the target subcategories and their class IDs\nsubcategories = load_subcategories(os.path.join(root_dir, 'data', 'categories_tinyplaces.txt'))\n\n# Select the samples from the train split of the TinyPlaces dataset\ntrain_samples = select_samples(subcategories, root_dir, 'train', 500)\n\n# Create the TinyPlaces datasets for binary and multiclass classification\ntinyplaces_binary_train = create_tinyplaces(train_samples, binary=True)\ntinyplaces_multi_train = create_tinyplaces(train_samples, binary=False)\n\n# Select the samples from the val split of the MiniPlaces dataset\nval_samples = select_samples(subcategories, root_dir, 'val', 50)\n\n# Create the TinyPlaces datasets for binary and multiclass classification\ntinyplaces_binary_val = create_tinyplaces(val_samples, binary=True)\ntinyplaces_multi_val = create_tinyplaces(val_samples, binary=False)\n\n# Save the TinyPlaces datasets to the data directory\ndata_dir = os.path.join(root_dir, 'data')\n\n\nwith open(os.path.join(data_dir, 'tinyplaces_binary_train.pkl'), 'wb') as f:\n    pickle.dump(tinyplaces_binary_train, f)\n\nwith open(os.path.join(data_dir, 'tinyplaces_multi_train.pkl'), 'wb') as f:\n    pickle.dump(tinyplaces_multi_train, f)\n\nwith open(os.path.join(data_dir, 'tinyplaces_binary_val.pkl'), 'wb') as f:\n    pickle.dump(tinyplaces_binary_val, f)\n\nwith open(os.path.join(data_dir, 'tinyplaces_multi_val.pkl'), 'wb') as f:\n    pickle.dump(tinyplaces_multi_val, f)\n\n\nclass TinyPlacesDataset(object):\n    def __init__(self, data_dict):\n        self.dataset = data_dict\n        self.num_samples = len(data_dict['data'])\n\n    def subsample(self, ratio=0.1, seed=None):\n        if seed is not None:\n            np.random.seed(seed)\n\n        nums = random.sample(range(self.num_samples), int(ratio * self.num_samples))\n        sub_dataset = {'data': self.dataset['data'][nums], 'label': self.dataset['label'][nums]}\n        subsampled_dataset = TinyPlacesDataset(sub_dataset)\n\n        return subsampled_dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-03T04:14:27.533599Z","iopub.execute_input":"2024-04-03T04:14:27.534008Z","iopub.status.idle":"2024-04-03T04:15:22.258637Z","shell.execute_reply.started":"2024-04-03T04:14:27.533978Z","shell.execute_reply":"2024-04-03T04:15:22.257755Z"},"editable":false,"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1z3B1GR7UtHZGrqNjUaep6thHwrN3IYSI\nFrom (redirected): https://drive.google.com/uc?id=1z3B1GR7UtHZGrqNjUaep6thHwrN3IYSI&confirm=t&uuid=ea50ff38-a7b4-4200-bb5f-8e3409252d98\nTo: /kaggle/working/data.tar.gz\n100%|█████████████████████████████████████████| 423M/423M [00:03<00:00, 121MB/s]\n","output_type":"stream"},{"name":"stderr","text":"Extracting tar.gz file: 100%|██████████| 526M/526M [00:13<00:00, 38.8MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nif device == torch.device('cuda'):\n    print(f'Using device: {device}. Good to go!')\nelse:\n    print('Please set GPU via Edit -> Notebook Settings.')\n    \nwith open(os.path.join(root_dir, 'data', 'tinyplaces_binary_train.pkl'), 'rb') as f:\n    binary_train = TinyPlacesDataset(pickle.load(f))\nwith open(os.path.join(root_dir, 'data', 'tinyplaces_binary_val.pkl'), 'rb') as f:\n    binary_val = TinyPlacesDataset(pickle.load(f))\nwith open(os.path.join(root_dir, 'data', 'tinyplaces_multi_train.pkl'), 'rb') as f:\n    multi_train = TinyPlacesDataset(pickle.load(f))\nwith open(os.path.join(root_dir, 'data', 'tinyplaces_multi_val.pkl'), 'rb') as f:\n    multi_val = TinyPlacesDataset(pickle.load(f))\n\n# Convert everything from numpy arrays to tensors and move them to the GPU using .cuda()\nfor dataset in [binary_train, binary_val, multi_train, multi_val]:\n    for k in ['data', 'label']:\n        dataset.dataset[k] = torch.tensor(dataset.dataset[k]).float().cuda()\n        \nfrom tqdm import tqdm\n\nfrom torch.utils.data import Dataset\nfrom PIL import Image\n\nclass MiniPlaces(Dataset):\n    def __init__(self, root_dir, split, transform=None, label_dict=None):\n        assert split in ['train', 'val', 'test']\n        self.root_dir = root_dir\n        self.split = split\n        self.transform = transform\n        self.filenames = []\n        self.labels = []\n        self.label_dict = label_dict if label_dict is not None else {}\n        if split == \"train\" or split == \"val\":\n            with open(os.path.join(root_dir, (\"train\" if self.split == \"train\" else \"val\") + \".txt\")) as f:\n                for line in f:\n                    line = line.rstrip().split()\n                    n = int(line[0][-12:-4])\n                    if n <= 900:\n                        self.filenames.append(os.path.join(line[0]))\n                        self.labels.append(int(line[1]))\n        if label_dict is None and split == \"train\":\n            with open(os.path.join(root_dir, \"train.txt\")) as f:\n                num = -1\n                for line in f:\n                    line = line.rstrip().split()\n                    if int(line[1]) > num:\n                        num += 1\n                        self.label_dict.update({int(line[1]): line[0][8:line[0].find(\"/\", 8)]})\n        if split == \"test\":\n            self.labels = os.listdir(os.path.join(root_dir, \"images\", \"test\"))\n            self.filenames = [\"test/\" + i for i in self.labels]\n\n    def __len__(self):\n        dataset_len = len(self.labels)\n        return dataset_len\n\n    def __getitem__(self, idx):\n        image = Image.open(os.path.join(self.root_dir, \"images\", self.filenames[idx]))\n        if not self.transform is None:\n            image = self.transform(image)\n        label = self.labels[idx]\n        return image, label\n\nfrom torchvision import transforms\n\ndata_transform = transforms.Compose([\n    transforms.Resize((64,64)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n])\n\ndata_root = os.path.join(root_dir, 'data')\nminiplaces_train = MiniPlaces(data_root, split='train', transform=data_transform)\nminiplaces_val = MiniPlaces(\n    data_root, split='val',\n    transform=data_transform,\n    label_dict=miniplaces_train.label_dict)\n\ndef train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs):\n    # Place model on device\n    model = model.to(device)\n    best_acc = 0\n    flag = False\n    for epoch in range(num_epochs):\n        model.train()  # Set model to training mode\n        # Use tqdm to display a progress bar during training\n        with tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{num_epochs}') as pbar:\n            for inputs, labels in train_loader:\n                # Move inputs and labels to device\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                # Zero out gradients\n                optimizer.zero_grad()\n                # Compute the logits and loss\n                logits = model(inputs)\n                loss = criterion(logits, labels)\n                # Backpropagate the loss\n                loss.backward()\n                # Update the weights\n                optimizer.step()\n                # Update the progress bar\n                pbar.update(1)\n                pbar.set_postfix(loss=loss.item())\n\n        # Evaluate the model on the validation set\n        avg_loss, accuracy = evaluate(model, val_loader, criterion, device)\n        if best_acc > accuracy:\n            if flag:\n                print(f'Validation set: Average loss = {avg_loss:.4f}, Accuracy = {accuracy:.4f}')\n                break\n            else:\n                flag = True\n        else:\n            best_acc = accuracy\n            flag = False\n        print(f'Validation set: Average loss = {avg_loss:.4f}, Accuracy = {accuracy:.4f}')\n\ndef evaluate(model, test_loader, criterion, device):\n    \"\"\"\n    Evaluate the classifier on the test set.\n\n    Args:\n        model: classifier to evaluate.\n        test_loader (torch.utils.data.DataLoader): Data loader for the test set.\n        criterion (callable): Loss function to use for evaluation.\n        device (torch.device): Device to use for evaluation.\n\n    Returns:\n        float: Average loss on the test set.\n        float: Accuracy on the test set.\n    \"\"\"\n    model.eval()  # Set model to evaluation mode\n\n    with torch.no_grad():\n        total_loss = 0.0\n        num_correct = 0\n        num_samples = 0\n\n        for inputs, labels in test_loader:\n            # Move inputs and labels to device\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            # Compute the logits and loss\n            logits = model(inputs)\n            loss = criterion(logits, labels)\n            total_loss += loss.item()\n\n            # Compute the accuracy\n            _, predictions = torch.max(logits, dim=1)\n            num_correct += (predictions == labels).sum().item()\n            num_samples += len(inputs)\n\n    # Compute the average loss and accuracy\n    avg_loss = total_loss / len(test_loader)\n    accuracy = num_correct / num_samples\n\n    return avg_loss, accuracy\n\ndef predict(model, test_dataloader):\n    \"\"\"\n    Evaluate the classifier on the test set.\n\n    Args:\n        model: classifier to evaluate.\n        test_loader (torch.utils.data.DataLoader): Data loader for the test set.\n        criterion (callable): Loss function to use for evaluation.\n        device (torch.device): Device to use for evaluation.\n\n    Returns:\n        float: Average loss on the test set.\n        float: Accuracy on the test set.\n    \"\"\"\n    out = []\n    for i in test_dataloader:\n        pic = i[0]\n        lab = torch.argmax(model.to('cpu')(pic))\n        out.append(lab.item())\n\n    return out\n\ndata_transform_flatten = transforms.Compose([data_transform, torch.flatten])","metadata":{"execution":{"iopub.status.busy":"2024-04-03T04:15:22.260688Z","iopub.execute_input":"2024-04-03T04:15:22.261028Z","iopub.status.idle":"2024-04-03T04:15:30.368758Z","shell.execute_reply.started":"2024-04-03T04:15:22.261002Z","shell.execute_reply":"2024-04-03T04:15:30.367696Z"},"editable":false,"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using device: cuda. Good to go!\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\n\nimport torchvision.transforms as v1\nfrom torchvision.io import read_image\n\n\nclass resBlock(nn.Module):\n    def __init__(\n        self,\n        channels,\n        input_size=(64,64),\n        dropout_rate=0.3,\n        kernel_size=3, stride=1, padding=1):\n\n        super().__init__()\n\n        self.process = nn.Sequential (\n            nn.Conv2d(channels, channels, kernel_size=kernel_size, stride=stride, padding=padding),\n            nn.MaxPool2d(3, stride=1, padding = 1),\n            nn.Dropout(p=dropout_rate),\n            nn.Conv2d(channels, channels, kernel_size=kernel_size, padding=padding),\n            nn.MaxPool2d(3, stride=1, padding = 1)\n        )\n\n\n    def forward(self, x):\n        left = self.process(x)\n        right = x\n\n        return (left + right)\n\n\n\nclass SlowConv(nn.Module):\n    def __init__(\n        self,\n        input_channels, conv_hidden_channels, conv_out_channels,\n        input_size=(64,64),\n        dropout_rate=0.25,\n        fc_out_channels=128, fc_hidden_layer = 256, num_classes=100,\n        kernel_size=3, stride=1, padding=1):\n\n      super().__init__()\n\n      self.preprocess = nn.Sequential (\n            nn.Conv2d(input_channels, conv_hidden_channels, kernel_size = 3, stride=stride, padding = padding),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(conv_hidden_channels, conv_out_channels, kernel_size = kernel_size, padding = padding),\n            nn.MaxPool2d(kernel_size=kernel_size, stride=1, padding = 1),\n            nn.Dropout(p=dropout_rate),\n        )\n\n\n      self.cnn = nn.Sequential (\n            resBlock(conv_out_channels, conv_out_channels, stride=stride, dropout_rate=dropout_rate),\n            resBlock(conv_out_channels, conv_out_channels, stride=stride, dropout_rate=dropout_rate),\n            resBlock(conv_out_channels, conv_out_channels, stride=stride, dropout_rate=dropout_rate),\n        )\n\n      self.linear = nn.Sequential (\n\n            nn.Linear(262144*2, fc_hidden_layer),\n            nn.ELU(),\n            nn.Dropout(p=dropout_rate),\n            nn.Linear(fc_hidden_layer, fc_hidden_layer),\n            nn.ELU(),\n            nn.Dropout(p=dropout_rate),\n            nn.Linear(fc_hidden_layer, int(fc_hidden_layer/2)),\n            nn.ELU(),\n            nn.Dropout(p=dropout_rate),\n            nn.Linear(int(fc_hidden_layer/2), num_classes),\n        )\n\n\n    def forward(self, x):\n\n        x = self.preprocess(x)\n\n        x = self.cnn(x)\n        x = x.flatten(1)\n        x = self.linear(x)\n\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T04:15:30.370292Z","iopub.execute_input":"2024-04-03T04:15:30.370766Z","iopub.status.idle":"2024-04-03T04:15:30.387907Z","shell.execute_reply.started":"2024-04-03T04:15:30.370733Z","shell.execute_reply":"2024-04-03T04:15:30.386970Z"},"editable":false,"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def initialize_weights(m):\n    if isinstance(m, nn.Conv1d):\n        nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n        if m.bias is not None:\n            nn.init.constant_(m.bias.data, 0)\n\n    elif isinstance(m, nn.BatchNorm1d):\n        nn.init.constant_(m.weight.data, 1)\n        nn.init.constant_(m.bias.data, 0)\n\n    elif isinstance(m, nn.Linear):\n        nn.init.kaiming_uniform_(m.weight.data)\n        nn.init.constant_(m.bias.data, 0)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T04:15:30.390482Z","iopub.execute_input":"2024-04-03T04:15:30.391073Z","iopub.status.idle":"2024-04-03T04:15:30.413071Z","shell.execute_reply.started":"2024-04-03T04:15:30.391037Z","shell.execute_reply":"2024-04-03T04:15:30.412100Z"},"editable":false,"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"### Create your DataLoader and use predict to get your model's predictions\nconv_train_dataset = MiniPlaces(\n    root_dir=data_root, split='train',\n    transform=data_transform)\nconv_val_dataset = MiniPlaces(\n    root_dir=data_root, split='val',\n    transform=data_transform)\nconv_train_loader = torch.utils.data.DataLoader(\n    conv_train_dataset, batch_size=64, num_workers=0, shuffle=True)\nconv_val_loader = torch.utils.data.DataLoader(\n    conv_val_dataset, batch_size=64, num_workers=0, shuffle=False)\n\nmodel = SlowConv(3,64,128,dropout_rate=0.3, fc_hidden_layer=1024)\n# model = model.apply(initialize_weights)\noptimizer = torch.optim.SGD(model.parameters(), momentum=0.8, weight_decay=0.001, lr=0.01)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-04-03T04:16:21.483393Z","iopub.execute_input":"2024-04-03T04:16:21.484168Z","iopub.status.idle":"2024-04-03T04:16:27.022126Z","shell.execute_reply.started":"2024-04-03T04:16:21.484136Z","shell.execute_reply":"2024-04-03T04:16:27.021342Z"},"editable":false,"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"! rm model-epoch1*.pth","metadata":{"execution":{"iopub.status.busy":"2024-04-03T08:18:50.841211Z","iopub.execute_input":"2024-04-03T08:18:50.841996Z","iopub.status.idle":"2024-04-03T08:18:52.388797Z","shell.execute_reply.started":"2024-04-03T08:18:50.841960Z","shell.execute_reply":"2024-04-03T08:18:52.387512Z"},"editable":false,"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#After 15 epoch, loss is small\n\noptimizer = torch.optim.SGD(model.parameters(), momentum=0.1, weight_decay=0.001, lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T06:25:23.004264Z","iopub.execute_input":"2024-04-03T06:25:23.004778Z","iopub.status.idle":"2024-04-03T06:25:23.013352Z","shell.execute_reply.started":"2024-04-03T06:25:23.004740Z","shell.execute_reply":"2024-04-03T06:25:23.011437Z"},"editable":false,"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for epoch in range(32,100,3):\n    train(model, conv_train_loader, conv_val_loader, optimizer, criterion, device, num_epochs=3)\n    torch.save(model, 'model-epoch'+str(epoch)+'.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-03T08:19:09.600975Z","iopub.execute_input":"2024-04-03T08:19:09.601681Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch 1/3: 100%|██████████| 1407/1407 [07:42<00:00,  3.04it/s, loss=0.00427]\n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.7443, Accuracy = 0.2333\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/3: 100%|██████████| 1407/1407 [07:43<00:00,  3.03it/s, loss=0.0159] \n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.7288, Accuracy = 0.2322\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/3: 100%|██████████| 1407/1407 [07:44<00:00,  3.03it/s, loss=0.00261]\n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.7297, Accuracy = 0.2289\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/3: 100%|██████████| 1407/1407 [07:44<00:00,  3.03it/s, loss=0.0179] \n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.7400, Accuracy = 0.2322\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/3: 100%|██████████| 1407/1407 [07:44<00:00,  3.03it/s, loss=0.0199] \n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.7351, Accuracy = 0.2356\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/3: 100%|██████████| 1407/1407 [07:43<00:00,  3.03it/s, loss=0.00576]\n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.7210, Accuracy = 0.2344\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/3: 100%|██████████| 1407/1407 [07:43<00:00,  3.04it/s, loss=0.00157]\n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.7143, Accuracy = 0.2344\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/3: 100%|██████████| 1407/1407 [07:43<00:00,  3.04it/s, loss=0.00601]\n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.6992, Accuracy = 0.2322\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/3: 100%|██████████| 1407/1407 [07:43<00:00,  3.04it/s, loss=0.0246] \n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.6923, Accuracy = 0.2322\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/3: 100%|██████████| 1407/1407 [07:44<00:00,  3.03it/s, loss=0.0964] \n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.6736, Accuracy = 0.2311\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/3: 100%|██████████| 1407/1407 [07:45<00:00,  3.02it/s, loss=0.000696]\n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.6816, Accuracy = 0.2344\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/3: 100%|██████████| 1407/1407 [07:45<00:00,  3.02it/s, loss=0.000719]\n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.6734, Accuracy = 0.2311\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/3: 100%|██████████| 1407/1407 [07:46<00:00,  3.02it/s, loss=0.00836]\n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.6534, Accuracy = 0.2356\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/3: 100%|██████████| 1407/1407 [07:45<00:00,  3.02it/s, loss=0.00319]\n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.6495, Accuracy = 0.2311\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/3: 100%|██████████| 1407/1407 [07:45<00:00,  3.02it/s, loss=0.0328] \n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.6493, Accuracy = 0.2344\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/3: 100%|██████████| 1407/1407 [07:44<00:00,  3.03it/s, loss=0.0194] \n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.6485, Accuracy = 0.2333\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/3: 100%|██████████| 1407/1407 [07:42<00:00,  3.04it/s, loss=0.0212] \n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.6153, Accuracy = 0.2333\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/3: 100%|██████████| 1407/1407 [07:41<00:00,  3.05it/s, loss=0.00943]\n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.6210, Accuracy = 0.2322\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/3: 100%|██████████| 1407/1407 [07:41<00:00,  3.05it/s, loss=0.00777]\n","output_type":"stream"},{"name":"stdout","text":"Validation set: Average loss = 4.6153, Accuracy = 0.2322\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/3:  31%|███       | 438/1407 [02:23<05:19,  3.04it/s, loss=0.00732]","output_type":"stream"}]}]}